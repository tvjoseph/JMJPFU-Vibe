---
title: "JMJPFU_Vibe"
output: html_notebook
---


# JMJPFU
# 3-Feb-2017
Lord help this venture. This is not my work but yours
This is the first working file for the Vibe project. 


# JMJPFU
### 27-Mar-2017 : Reference URLS

Scrapping web with rvest : https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29


This file is to define the overall process. This document will be updated regularly to reflect the right process

Lord this is to test the new push command after the creation of remote

### JMJPFU
### 6-Feb-2017

## Step 1 : Scrapping the web and getting data


The first step is to scrap the websites and get data related to hotesl. This data scrapping will be used for creating the training data set and also as a major step in the process.

### Step 1a : Loading the library files


```{r}
library(rvest)
library(dplyr)

```

### Step 1b: Defining the url and then scrapping the website

```{r}
# Hilton Chennai

url <- paste0("https://www.tripadvisor.in/ShowUserReviews-g304556-d1597314-r445001902-Hilton_Chennai-Chennai_Madras_Chennai_District_Tamil_Nadu.html#CHECK_RATES_CONT")

url1 <- paste0("https://www.tripadvisor.in/Hotel_Review-g304556-d1597314-Reviews-or20-Hilton_Chennai-Chennai_Madras_Chennai_District_Tamil_Nadu.html#REVIEWS")

chenHilton <- read_html(url)

hiltRev <- chenHilton %>% html_nodes(".partial_entry") %>% html_text()

hiltRev1 <- chenHilton %>% html_nodes(".partial_entry") %>% html_text()


hiltRev <- unlist(hiltRev,hiltRev1) # To create a combined list



```


https://www.tripadvisor.in/Hotel_Review-g304556-d1597314-Reviews-Hilton_Chennai-Chennai_Madras_Chennai_District_Tamil_Nadu.html#REVIEWS

A loop for the above process

```{r}

for(i in seq(20,1140,10)){
  
  # Creating the URL which loops over each page
  
  url <- paste0("https://www.tripadvisor.in/Hotel_Review-g304556-d1597314-Reviews-or",i,"-Hilton_Chennai-Chennai_Madras_Chennai_District_Tamil_Nadu.html#REVIEWS")
  
  # Reading the URL data using the package
  
  chenHilton <- read_html(url)
  
  # Extracting the text

temp <- chenHilton %>% html_nodes(".partial_entry") %>% html_text()

# Consolidating the text

hiltRev <- list(hiltRev,temp) # To create a combined list

hiltRev <- unlist(hiltRev)
  
}

hiltRev[44]
```

It seems the odd numbered are usually the guest comments and the even numbered ones the hotel comments. Let try taking only the odd numbered reviews. Let us take only the guest comments first

```{r}

# Guest comments
for(i in seq(39,2281,2)){
  
  temp <- hiltRev[i]
  
  hiltRev1 <- list(hiltRev1,temp)
  
  hiltRev1 <- unlist(hiltRev1)
  
}

hiltRev1[1000]

```

## Step 2 : Creating templates

Once the data is obtained, the next task is to create templates for each emotions. The process of creating the templates is as follows

1. From the existing text, create sets of unigrams, bigrams, trigrams and quadragrams
2. Create seperate dataframes for storing these n-grams.
3. Once dataframes are created, manaully classify them according to emotions
4. Make a baseline templates for various emotions and then keep updating the templates over time


### Step 2a : Concatinating the text and creating seperate n-grams

```{r}
library(rvest)
library(dplyr)
library(tm)
library(ngram)
library(stringr)
library(wordcloud)
```

The below code will create the consolidated text of all reviews.


```{r}
# Creating consolidated text
for(i in seq(3,1121,2)){
  
  temp <- concatenate(hiltRev1[i],hiltRev1[i+1])

hosText <- concatenate(hosText,temp)
  
}



```

Cleaning up the text is the next task. The below function cleans up the text.

```{r}
cleansamp <- function(corpus){
  #strip whitespace
  corpus <- gsub("\\s+"," ",corpus) 
  #remove punctuation
  corpus <- gsub("[[:punct:]]", "", corpus)
  #remove numbers
  corpus <- gsub("[[:digit:]]+", "", corpus)
  #remove profanity
  #corpus <- gsub(x = corpus, pattern = paste(profanity, collapse = "|"), replacement = "") 
  #lowercase
  corpus <- tolower(corpus)
  corpus
  
  
      }
```

Running the above function to create the cleaned up text

```{r}
hosClean <- cleansamp(hosText)

nchar(hosClean)
```


Creating unigrams,bigrams, trigrams and quadragrams from the cleaned up text

```{r}
hosUni <- get.ngrams(ngram(hosClean,n=1))
hosBi <- get.ngrams(ngram(hosClean,n=2))
hosTri <- get.ngrams(ngram(hosClean,n=3))
hosQuad <- get.ngrams(ngram(hosClean,n=4))

```

Once the n-grams are created, the next task is to go through the n grams manually and classify them.

```{r}

hosUni <- data.frame(hosUni)
hosUni$Class <- 0

hosBi <- data.frame(hosBi)
hosBi$Class <- 0

hosTri <- data.frame(hosTri)
hosTri$Class <- 0

hosQuad <- data.frame(hosQuad)
hosQuad$Class <- 0

```

Let us write the n-grams into a csv format and then mechanically classify the same

```{r}
write.csv(hosQuad,"hosQuad.csv")
```

### JMJPFU
### 10-Feb-2017

Let us now implement the vector similarity concepts. The below are the tasks which needs to be done.

1. Make a list of charachteristics which are associated with a hotel. For example
  Room, Food, Restaurant, Staff, Lobby, Reception, Transfer, Facilities, Cleanliness, Recommend etc
  
2. For each of the charachteristics make a template for each emotion
  Satisfied, Delighted, OK, Frustrated, Angry, Sue etc
3. The template for each charachteristic-emotion combiation will be the most common associated words and its frequencies.
4. For making the template, different samples of data for each charachteristic-emotion pair is identified and an average frequency score is computed.
5. Once the templates are ready, training data has to be prepared. Features have to be extracted based on the charachteristic-emotion combination pair and its similarity vector with each of the template.
6. Any new data set will first have to be converted to the above set of features and then prediction of the probability of emotions will have to be done.
7. We should also think about prediction at the charachteristic level

Let us now implement one by one each of the above ideas in seperate seperate notebooks.

### JMJPFU
### 16-Feb-2017

Scrapping some negative reviews for hotels

```{r}
#url <- paste0("https://www.tripadvisor.in/ShowUserReviews-g304556-d589477-r459899087-The_Raintree_Hotel_St_Mary_s-Chennai_Madras_Chennai_District_Tamil_Nadu.html#CHECK_RATES_CONT")

url1 <- paste0("https://www.tripadvisor.in/ShowUserReviews-g304556-d589477-r336536821-The_Raintree_Hotel_St_Mary_s-Chennai_Madras_Chennai_District_Tamil_Nadu.html#REVIEWS")


hotelBad <- read_html(url1)

#list1 <- hotelBad %>% html_nodes("div p") %>% html_text()

# Selecting only the relevant text

list2 <- hotelBad %>% html_nodes("div p") %>% html_text()

#badRev <- list(list1,list2)

#badRev <- unlist(badRev) # To create a combined list

# Continuous attempts

badRev <- list(badRev,list2)
badRev <- unlist(badRev)

badRev[1:50]

# Filter on emotions

# Delighted # c(3,)
# Satisfied # c(2,)
# OK #
# Disappointment # c(1,)
# Angry #

badrevDf <- data.frame(badRev)
write.csv(badrevDf,"reviewTrain1.csv")
getwd()

# Creating a new column for classification

badrevDf$class <- 0

```

Next number 45

# JMJPFU
## 21-Feb-2017

Below we are reviewing each comment and classifying it according to the emotion displayed

```{r}
# Delighted # c(3,),# Satisfied # c(2,),# OK #,# Disappointment # c(1,),# Angry #
badrevDf$badRev[256:266]
badrevDf$class[256:266] <- c(1,1,3,0,1,2,2,0,2,2,0)
```

# JMJPFU
## 23-Feb-2017
1. Completed so far - Till row 266

```{r}
badRev[237]
```
Now that we have classified the text file, let us store the relevant data in various dataframes

```{r}
delightDf <- badrevDf %>% filter(class==1)
satisDf <- badrevDf %>% filter(class==2)
okDf <- badrevDf %>% filter(class==3)
dissatDf <- badrevDf %>% filter(class==4)
angryDf <- badrevDf %>% filter(class==5)

```

# JMJPFU
<<<<<<< HEAD
### 26-Mar-2017

This is the new beginning of the vibe project from home. Lord save this and guide this venture
=======
### 24-Feb-2017

Listed below are the templates created for each of the artefact

1: Room : Satisfied - roomSatCon , Angry - roomAngTemp
2: Restaurant : 


# JMJPFU
### 27-Feb-2017

Let us consolidate the templates further after classifying the text

```{r}

url1 <- paste0("https://www.tripadvisor.in/ShowUserReviews-g297605-d2517469-r330022559-Sukhmantra_Resort_and_Spa-Candolim_Bardez_Goa.html#REVIEWS")


#https://www.tripadvisor.in/ShowUserReviews-g297605-d2517469-r407738122-Sukhmantra_Resort_and_Spa-Candolim_Bardez_Goa.html#CHECK_RATES_CONT


hotelRev <- read_html(url1)


# Selecting only the relevant text

#list2 <- hotelRev %>% html_nodes("div p") %>% html_text()

#list2 <- hotelRev %>% html_nodes("#REVIEWS") %>% html_text()

list2 <- hotelRev %>% html_nodes("p") %>% html_text()

#badRev <- list(list1,list2)

#badRev <- unlist(badRev) # To create a combined list

# Continuous attempts

hotelData <- list(hotelData,list2)
hotelData <- unlist(hotelData)



#hotelrevDf <- data.frame(hotelRev)

# Creating a new column for classification

#hotelrevDf$class <- 0


```

# JMJPFU
### 10-Mar-2017

Today let us try some other hotel URL and try to get more data for classification. Will use the same method as above.

# JMJPFU
<<<<<<< HEAD
### 27-Mar-2017

Now that we have scrapped some of the data. Let us look at labelling them and then use it for creating the training set.

```{r}
hoteldatDf <- matrix(nrow=length(hotelData),ncol = 1)

hoteldatDf <- data.frame(hoteldatDf)

hoteldatDf$class <- 0
```

Let us try classifying the new text

```{r}
# Delighted # c(3,),# Satisfied # c(2,),# OK #,# Disappointment # c(1,),# Angry #
hoteldatDf$hoteldatDf[75:84]
hoteldatDf$class[75:84] <- c(5,5,5,4,3,3,4,0,0,0)


```


Now to take the classified data

```{r}
# Taking subset till 165 as the others were already done
tempDat <- hoteldatDf[85:165,]

temp1 <- tempDat %>% filter(class==1) 
temp2 <- tempDat %>% filter(class==2)
temp3 <- tempDat %>% filter(class==3)
temp4 <- tempDat %>% filter(class==4)
temp5 <- tempDat %>% filter(class==5)

# Names of the dataframes

names(temp1) <- names(temp2) <-  names(temp3) <-  names(temp4) <-  names(temp5) <- c("badRev", "class" )

# Combining with the existing data

delightDf <- rbind(delightDf,temp1)
satisDf <- rbind(satisDf,temp2)
okDf <- rbind(okDf,temp3)
dissatDf <- rbind(dissatDf,temp4)
angryDf <- rbind(angryDf,temp5)


# 
```

=======
### 26-Mar-2017

Lord bless this venture with your Grace and Wisdom.
<<<<<<< HEAD

```{r}
hotelData[160:165]
```
=======
>>>>>>> 15a87e35d8137eefac3d72d0f21e786f53f0da31

# JMJPFU
### 28-Mar-2017

Today we will try creating the features for the project. These are the steps we will do

1. Complete the templates for all the emotions for all the selected archetypes.
2. Based on the template, create features for each text and then classify them.
3. Prepare test cases and training cases
4. Spot checking the models
5. Look for predictions.
6. Fine tune the predictions by doing feature engineering.

# JMJPFU
### 30-Mar-2017

Once that the templates are created. We need to create a consolidated template which will be used for similarity scoring. The process for this is as follows.

1. Take a template and then get a count of the columns where there is frequency values.
2. Multiply the counts with the average frequency of each word and get a weighted frequency
3. Convert each of the weighted frequency into a probability space by dividing each weighted frequency with the sum of all weighted frequencies.
4. Sort the words based on the probabilities and then filter out the non relevant ones.
5. After this create the feature engineered data frames

>>>>>>> e18546578f49926f356a8f22bef69a0901f84b42

# JMJPFU
### 5-April-2017

Once the consolidated templates are created. The next task is to create feature maps for text based on the similarity measures of each template. The steps would be as follows

1. Listing all the variables involved in the process

roomdel, resdel,staffdel, lobbydel, recepdel, trandel,facildel,reccodel

roomSat, foodSat , restSat , staffSat , lobbySat , receptionSat , facilSat, locaSat

roomok, resok,staffok ,lobbyok , recepok, facilok

roomdis, restdis, staffdis 

roomAng,restAng,staffAng 


2. Second process is to first take a chunk of text and then compare against each of these templates and extract the relevant similarity scores against each of these variables

3. The similarity scores will thereby be populated in the feature space. 


