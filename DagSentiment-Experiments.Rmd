---
title: "JMJPFU-DagSentiment-Experimentation"
output: html_notebook
---

# JMJPFU
### 14-May-2017

This is the notebook for doing experiments

```{r}
library(rvest)
library(dplyr)
library(tm)
library(ngram)
library(stringr)
library(wordcloud)
```

### Importing data set

```{r}
hotText <- Hotel_reviews[1,1]

paste(hotText)
```

### Step 1 : Let us now create some aspect Dictionaries

```{r}
## Aspect Dictionary: Food

foodDict <- list()

foodDict <- append(foodDict,"food")
foodDict <- append(foodDict,c("dishes","icecream","fish"))

foodDict <- unlist(foodDict)

########## Aspect Dictionary : Ambience

ambDict <- c("ambience","atmosphere")

########## Aspect Dictionary : Service

serDict <- c("service","waiter")

########## Aspect Pricing :

pricDict <- c("price","pricing","cost","expense")

```

### Creating sentiment dictionaries

```{r}
# Creating a positive dictionary
postDic <- c("consistent","good","fun","fast","consistently")

# Creating a negative dictionary

negDic <- c("bad","nonsense","no","exorbitant")


```






### Step 1 : Splitting as per different lines

```{r}

# Doing the split sentence by sentence

textSplit <- str_split(hotText,"[.]")

# Unlisting the split so that it is a list of sentences

textSplit <- unlist(textSplit)

# Finding the sentence length

sentLength <- length(textSplit)

# Looping over the list of sentences

for(i in 1: sentLength){
  
  textSamp <- textSplit[i]
  
  # Let us clean up the text
  
  textSamp <- cleansamp(textSamp)
  
  # Converting to a corpus
  
  textCorp <- Corpus(VectorSource(textSamp))
  
  # Let us remove the stop words
  
  textCorp <- tm_map(textCorp,removeWords,c("the","was","i","at","a","when","is","and","has","for","of","are","to","an","it","in","be","if","on","since","as","had","so","he","him","me","her","she","its","that","its","been","he","there"))
  
  textCorp <- tm_map(textCorp,stripWhitespace)
  
 # Getting back the clean text
  
  textClean <- textCorp1[[1]]$content
  
  textClean <- stripWhitespace(textClean)
  
 # Split the text again based on the spaces 
  
  cleantxtSplit <- str_split(textClean," ")
  
  # Unlisting the text again
  
  cleantxtSplit <- unlist(cleantxtSplit)
  
  ############################### DAG Extraction Layer ######################
  
  # length of DAG text
  
  dagLen <- length(cleantxtSplit)
  
  # Checking if there are any intersecting items from food Dictionary
  
  foodMatch <- intersect(cleantxtSplit,foodDict)
  
  # Find the index of the matching text
  
  if(length(foodMatch) > 0){
    
    matchId <- match(foodMatch,cleantxtSplit)
    
    # The result of the above is a list of index for matching words in the dictionary. If the match is found the index is listed there. Else we get only NA's 
  
  matchId <- matchId[!is.na(matchId)] # This gets only the Non NA id's
    
    ########## Next start the recursive checking for sentiment from the sentiment dictionary #####
  
  if(length(matchId) > 0){  
    
    indLen <- length(matchId) # Find the total number of indexes where the dictionary is matching
    
    for(j in 1:indLen){
      
      tempInd <- matchId[j] # Getting the first index
      
      # Now starting a while index so that the index recursively passess through the DAG
      
      tempInd <- tempInd + 1 # Incrementing the index number so that it starts comparing with the next word onward
      
      recDag <- "N" # Initializing a neutral polarity
      
      while(tempInd <= dagLen){
        
        # Finding the polarity recursively
        
        if(length(intersect(cleantxtSplit[tempInd],postDic)) > 0){recPost <- "P"}else     if(length(intersect(cleantxtSplit[tempInd],negDic)) > 0){recDag <- "Ne" }else{recPost <- "N"}
        
        
        # Below is to find the new polarity of the Dag
        
        if(recPost == "P" & recDag == "N"){recDag <- "P"}else if(recPost == "Ne" & recDag == "N"){recDag <- "Ne"}else if(recPost == "N" & recDag == "N"){recDag <- "N"}else if(recPost == "P" & recDag == "P"){recDag <- "P"}else if(recPost == "Ne" & recDag == "P" ){recDag == "Ne"}else if(recPost == "N" & recDag == "P"){recDag <- "P"}else{recDag == "Ne"}
        
        tempInd <- tempInd + 1 # Incrementing the tempInd inside the loop
        
        # Checking if we have reached any other aspect
        
        asCheck <- length(intersect(cleantxtSplit[tempInd],ambDict))
        if(asCheck > 0){break}
        asCheck <- length(intersect(cleantxtSplit[tempInd],serDict))
        if(asCheck > 0){break}
        asCheck <- length(intersect(cleantxtSplit[tempInd],pricDict))
        if(asCheck > 0){break} # If a next index is found come out of the while loop
        
      } # End of the while loop
      
      
    } # End of Inner for loop looping over the length of indexes
    
    
    
    
    } # End of the second if Loop for looping over the matching index
    
    } # End of the first if loop for foodMatch
  
  
  ################## $$$$$$$$$$$$$$$
  
  # At this point, enter the overall sentiment of the food search
  
  
  
  
  
} # End of the first for loop



```
# Tomorrow

1. Create a function for the aspect - sentiment search and the DAG updater
2. Update the DAG score in a data frame. Based on the number of positive words create a feature for the update
3. Create DAG updater for all sentiments
