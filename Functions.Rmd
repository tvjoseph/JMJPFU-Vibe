---
title: "JMJPFU-Functions"
output: html_notebook
---

## JMJPFU
### 10-Feb-2017

### Function 1 : Function for converting List of text into a Document Term Matrix

Use of the function : For Template creation

```{r}

tdmCreator <- function(textList){
  
  # textList : This is a list of text which has to be analysed further
  
  
library(SnowballC)
library(RWeka)
library(rJava)
library(RWekajars)
library(tm)  
  
# Converting all the list elements to a dataframe
textDf <- do.call("rbind",lapply(textList,as.data.frame)) # hiltSatisfacDf > textDf
# Converting the factors to character
textDf <- data.frame(lapply(textDf,as.character),stringsAsFactors = FALSE)
# Providing a name to the text column
names(textDf) <- "text"
# Converting this into a corpus  
textCorp <- Corpus(VectorSource(textDf$text)) #  hiltSatCorp > textCorp 
# Converting to lowercase
textCorp <- tm_map(textCorp,tolower) 
# Remove punctuations
textCorp <- tm_map(textCorp,removePunctuation)
# Remove numbers
textCorp <- tm_map(textCorp,removeNumbers)
# Removing stopwords
textCorp <- tm_map(textCorp,removeWords,stopwords('english'))
# Doing the stemming
textCorp <- tm_map(textCorp,stemDocument)
# Converting the text to Plaintext
 textCorp <- tm_map(textCorp, PlainTextDocument)
# Converting to a corpus for making TDM
textCorp <- Corpus(VectorSource(textCorp))
# Creating TermDocumentMatrix
textDtm <- TermDocumentMatrix(textCorp)

return(textDtm)
 
  
} # End of the function


```


## Function 2 : Creating the template frequencies 

This function is to create the initial template for the frequencies
Use : This will be used in the SatisfiedTemplate or any other templates

```{r}

templateCreate <- function(tdm,arch,thresh){
  
  # This is the function to create a template DF from the term document and a charachteristic word
  # tdm : Term document matrix which needs to be converted to the matrix
  # arch : This is the text which denotes the archetype of the hotel like Room, Food, etc. This will be a character
  # thresh : This is the threshold within which the frequencies have to be found out. This will be numeric less or equal to 1
  
  library(dplyr)
  # Finding the association from the tdm
  archEmo <- findAssocs(tdm, arch,thresh) # roomSat > archEmo
  # Converting the list element into a data frame
  assocDf <- data.frame(archEmo[[1]])
  # Naming the first column as frequency
  names(assocDf) <- "freq"
  # Making the words as the second variable
  assocDf$word <- rownames(assocDf)
  # Re-ordering the variables
  assocDf <- assocDf %>% select(word,freq)
  
  row.names(assocDf) <- NULL
  
  return(assocDf)
}


```

# JMJPFU
## 13-Feb-2017

### Fu
function 3 : Overencompossing Function to create template

The below is an overencompassing function which integrates lots of functions and scripts to create template

```{r}

conTemplate <- function(scrRev,num1,num2,char1,char2,num3,name1,charEmoCon){
  
  
library(SnowballC)
library(RWeka)
library(rJava)
library(RWekajars)
library(tm) 
  
  # scrRev : This is the text which is scrapped from the net
  # num1, num2 : There are the anchor points of the text i.e start point of the text and end point of the text
  # char1 : This is the artefact of the domain which needs to be passed to create the termDocumentmatrix data frame
  # char2 : This is the second character of the above which could be a plural or a different form of the same word
  # num3 : This is the threshold frequency which we want the termDocumentMatrix to be
  # name1 : A character term which needs to be given to the term Document dataframe
  # charEmoCon : This is a template which needs to be updated with more columns of frequencies
  
  # Getting the relevant text
  dfEmotion <- scrRev[num1:num2] # hiltSatisfaction > dfEmotion hiltRev1 > scrRev 
  
  # Creating the Term document matrix
  satTdm <- tdmCreator(dfEmotion) # Calling the function tdmCreator
  
  # Creating the Frequency dataframe
  
charEmoTemp1 <- templateCreate(satTdm,char1,num3) # roomSatTemp1 > charEmoTemp1 'rooms' > char1 , 

names(charEmoTemp1)[2] <- name1

if(char2 != "NA" ){ charEmoTemp2 <- templateCreate(satTdm,char2,num3)
names(charEmoTemp2)[2] <- name1
charEmoTemp1 <- rbind(charEmoTemp1,charEmoTemp2)

} # End of the if condition # roomSatTemp2 > charEmoTemp2

# Consolidating the final document with merge

charEmoCon <- merge(charEmoCon,charEmoTemp1,all = TRUE ) # roomSatCon > charEmoCon


return(charEmoCon) # Returning the consolidated dataframe
  
  
  
  
} # End of the function


```


#JMJPFU
### 15-May-2017

## Function 4 : Recursive scanning function

This function is to recursively scan the text files and create relevant features

```{r}

recScanner <- function(cleantxtSplit,aspect){
  
  # CleantxtSplit : This is the text which needs to be recursively scanned
  # aspect : This is a charachter which is checked to find out the right aspect
  # foodDict : This is the dictionary if the aspect is food
  ### Body of the function ###
  
  dagLen <- length(cleantxtSplit) # Find the length of the text to be recursively scanned
  
  # Checking if there are any intersecting items from respective aspect Dictionary
  
  ## change : foodMatch => aspectMatch
  
  # Doing a intersect to find the matching words in the passed text with the dictionary
  
  if(aspect == "food"){aspectMatch <- intersect(cleantxtSplit,foodDict)  }else if(aspect == "ambience" ){aspectMatch <- intersect(cleantxtSplit,ambDict)}else if(aspect == "service"){aspectMatch <- intersect(cleantxtSplit,serDict) }else if(aspect == "price"){aspectMatch <- intersect(cleantxtSplit,pricDict)}
    
  # Find the index of the matching text
  
  if(length(aspectMatch) > 0){  
    
    # Find the index of the aspect in the original text.The result of the below is a list of index for matching           words in the dictionary. If the match is found the index is listed there. Else we get only NA's 
    
    matchId <- match(aspectMatch,cleantxtSplit)
    
    # The below code is to get only the Non NA id's
    
    matchId <- matchId[!is.na(matchId)] 
  
    ########## Next start the recursive checking for sentiment from the sentiment dictionary #####
    
    if(length(matchId) > 0){ 
      
      # Find the total number of indexes where the dictionary is matching
      
      indLen <- length(matchId)
      
      # Start a for loop to recursively start another scanning of text from the index of matching aspect in the text
  
      for(j in 1:indLen){
        
        # Start a empty data frame to store the DAGs for each index
        
        dagStore <- data.frame(matrix(nrow=indLen,ncol=1))
        
        # Getting the first index and Incrementing the index number so that it starts comparing with the next word            onward
        
        tempInd <- matchId[j] + 1
        
        # Initializing a neutral polarity as default to the Dag polarity tagger. In addition initializing positive          counter and also negative counter
        
        recDag <- "N" 
        Pcou <- 0
        Ncou <- 0
        
        # Now starting a while index so that the index recursively passess through the DAG
        
        while(tempInd <= dagLen){
          
          
          
          # Finding the polarity recursively for the relevant word in the text
          
          if(length(intersect(cleantxtSplit[tempInd],postDic)) > 0){recPost <- "P"}else if(length(intersect(cleantxtSplit[tempInd],negDic)) > 0){recPost <- "Ne" }else if(length(intersect(cleantxtSplit[tempInd],polDic)) > 0){recPost <- "Pc"}else{recPost <- "N"}
  
          # Based on the polarity of the word the DAG is updated for polarity
        
        if(recPost == "P" & recDag == "N"){recDag <- "P";Pcou <- Pcou + 1}else if(recPost == "Ne" & recDag == "N"){recDag <- "Ne";Ncou <- Ncou + 1}else if(recPost == "N" & recDag == "N"){recDag <- "N"}else if(recPost == "P" & recDag == "P"){recDag <- "P";Pcou <- Pcou + 1}else if(recPost == "Ne" & recDag == "P" ){recDag == "Ne";Ncou <- Ncou + 1}else if(recPost == "N" & recDag == "P"){recDag <- "P"}else if(recPost == "P" & recDag == "Pc"){recDag <- "Ne";Ncou <- Ncou + 1}else if(recPost == "Ne" & recDag == "Pc"){recDag <- "P";Pcou <- Pcou + 1}else if(recPost == "N" & recDag == "Pc"){recDag <- "N"}else if(recPost == "Pc"){recDag <- "Pc"}else{recDag == "Ne"}
          
          # Incrementing the tempInd inside the loop
          
          tempInd <- tempInd + 1 
          
          # Checking if we have reached any other aspect. This section needs to be updated based on the new aspects             which will get introduced
        if(aspect == "food"){
          
          asCheck <- length(intersect(cleantxtSplit[tempInd],ambDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],serDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],pricDict))
          if(asCheck > 0){break} # If a next index is found come out of the while loop
          
        }else if(aspect == "ambience"){
          
          asCheck <- length(intersect(cleantxtSplit[tempInd],foodDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],serDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],pricDict))
          if(asCheck > 0){break} # If a next index is found come out of the while loop
          
        }else if(aspect == "service"){
          
          asCheck <- length(intersect(cleantxtSplit[tempInd],foodDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],ambDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],pricDict))
          if(asCheck > 0){break}
        }else if(aspect == "price"){
          
          asCheck <- length(intersect(cleantxtSplit[tempInd],foodDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],ambDict))
          if(asCheck > 0){break}
          asCheck <- length(intersect(cleantxtSplit[tempInd],serDict))
          if(asCheck > 0){break}
        }
            } # End of the while loop
        
        # Storing the final dag in the dag storer
        
        dagStore[j,1] <- recDag
        
      } # End of Inner for loop looping over the length of indexes
    
    
    } # End of the second if Loop for looping over the matching index
    
    list(dagStore = dagStore,PCount = Pcou,Ncount = Ncou)
    
    }else{
      
      dagStore[1,1] <- NA
     
      list(dagStore = dagStore,PCount = 0,Ncount = 0) 
      
    } # End of the first if loop for aspectMatch
        
    
  
  
} # End of the function

```

# JMJPFU
### 11-June-2017

Let us make a new function to clean the reviews

```{r}

revClean <- function(textSamp){
  
 # Let us clean up the text
  
  textSamp <- cleansamp(textSamp)
  
  # Converting to a corpus
  
  textCorp <- Corpus(VectorSource(textSamp))
  
  # Let us remove the stop words
  
  textCorp <- tm_map(textCorp,removeWords,c("the","was","i","at","a","when","is","and","has","for","of","are","to","an","it","in","be","if","on","since","as","had","so","he","him","me","her","she","its","that","its","been","he","there"))
  
  textCorp <- tm_map(textCorp,stripWhitespace)
  
 # Getting back the clean text
  
  textClean <- textCorp[[1]]$content
  
  textClean <- stripWhitespace(textClean)
  
 # Split the text again based on the spaces 
  
  cleantxtSplit <- str_split(textClean," ")
  
  # Unlisting the text again
  
  cleantxtSplit <- unlist(cleantxtSplit)
  
}
```

   
      
      
      
        
        
        
        
        
        
        
        
        
        
      
      
    
```{r}

recScanner(cleantxtSplit,"food")

```








